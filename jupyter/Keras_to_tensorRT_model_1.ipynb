{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "import tensorflow.keras as tfk\n",
    "import random\n",
    "import os\n",
    "import pathlib\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.compat.v1.graph_util import convert_variables_to_constants\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import random\n",
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.getcwd()\n",
    "keras_model_pfad = \"keras_model_0.h5\"\n",
    "tf_model_pfad = os.path.join(base_path,'../Models/tensorflow/Tensor_')\n",
    "fr_graph_tf_model = tf_model_pfad + \"frozen_model_tf.pb\"\n",
    "fr_graph_trt_model =os.path.join(base_path,'../Models/TensorRT/frozen_model_trt.pb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras zu Tensorflow-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras-Model wird hochgeladen!\n",
      "WARNING:tensorflow:From /home/kamgo/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/kamgo/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/kamgo/py36/lib/python3.6/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Tensor(\"conv2d_input:0\", shape=(?, 48, 48, 3), dtype=float32)\n",
      "Umwandlung vom Keras zu Tensor-Model..\n",
      "Umgewandelt und gespeichert!\n"
     ]
    }
   ],
   "source": [
    " \"\"\"\n",
    "diese Funktion wird ein Keras-Model in ein Tensor-Model\n",
    "Umwandeln\n",
    "\"\"\"\n",
    "\"\"\" da die Batchnormalisation-Parameter im Keras\n",
    "als trainable parameter gespeichert sind, mussen wird diese als\n",
    "non_trainable zur√ºcksetzen\n",
    "\"\"\"\n",
    "tf.keras.backend.set_learning_phase(0)\n",
    "\n",
    "print(\"Keras-Model wird hochgeladen!\")\n",
    "try:\n",
    "    model = load_model(keras_model_pfad)\n",
    "except FileNotFoundError:\n",
    "    print(\"Kein .h5-Datei wurde gefunden!\")\n",
    "    exit()\n",
    "# get input und output des models for tensorflow improvement\n",
    "input_model = model.inputs[0]\n",
    "print(input_model)\n",
    "output_model = model.outputs[0]\n",
    "\n",
    "print(\"Umwandlung vom Keras zu Tensor-Model..\")\n",
    "# model.summary()\n",
    "# [print(node.op.name) for node in model.outputs]\n",
    "saver = tf.train.Saver()\n",
    "# keras session wird als tf- Session gelesen!\n",
    "sess = tf.keras.backend.get_session()\n",
    "# die Graph der Tf-Session wird gespeichert\n",
    "save_path = saver.save(sess, tf_model_pfad)\n",
    "tf.keras.backend.clear_session()\n",
    "print(\"Umgewandelt und gespeichert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Tf-Model zu tf-Frozen-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kamgo/py36/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from /home/kamgo/Verkehrszeichenerkennung/jupyter/../Models/tensorflow/Tensor_\n",
      "['dense_1/Softmax']\n",
      "Frozen model ergestellt!\n",
      "WARNING:tensorflow:From <ipython-input-4-b985c1f8af51>:31: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
      "WARNING:tensorflow:From /home/kamgo/py36/lib/python3.6/site-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "INFO:tensorflow:Froze 16 variables.\n",
      "INFO:tensorflow:Converted 16 variables to const ops.\n",
      "speichert!\n",
      "WARNING:tensorflow:From <ipython-input-4-b985c1f8af51>:35: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "Frozen model wurde gespeichert!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " das aus Keras-Model Generierte Tensort-Model(oder ein normales\n",
    " Tensor-Model) wird hochgeladen\n",
    " und in frozen Graph umgewandelt\n",
    " input : tensor-Model\n",
    " ouput : frozen graph .pd\n",
    "\"\"\"\n",
    "# set the memory fraction eg. 0.2 meaning tf use 20% of gpu and\n",
    "# the will bei Trt\n",
    "gpu_option = tf.GPUOptions(per_process_gpu_memory_fraction=0.5)\n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_option)) as sess:\n",
    "    # import of meta graph fo tensorflow model\n",
    "    path_meta_file = tf_model_pfad + \".meta\"\n",
    "    saver = tf.train.import_meta_graph(path_meta_file)\n",
    "    # print(graph)\n",
    "    # exit()\n",
    "    # restore the weights to the meta graph\n",
    "    saver.restore(sess, tf_model_pfad)\n",
    "\n",
    "    # specify the tensor output of the model\n",
    "    output_models = [n.name for\n",
    "                     n in tf.get_default_graph().as_graph_def().node\n",
    "                     if \"dense_1/Softmax\" in n.name]\n",
    "    print(output_models)\n",
    "    # print(output_models)\n",
    "    # exit()\n",
    "    # convert to frozen model\n",
    "    print(\"Frozen model ergestellt!\")\n",
    "    frozen_graph = convert_variables_to_constants(sess,\n",
    "                                                  tf.get_default_graph().as_graph_def(),\n",
    "                                                  output_node_names=[\"dense_1/Softmax\"])\n",
    "\n",
    "    # save the frozen graph\n",
    "    print(\"speichert!\")\n",
    "    with gfile.FastGFile(fr_graph_tf_model, \"wb\") as f:\n",
    "        f.write(frozen_graph.SerializeToString())\n",
    "    print(\"Frozen model wurde gespeichert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow-Frozen zu TensorRT-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Linked TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Loaded TensorRT version: (0, 0, 0)\n",
      "INFO:tensorflow:Running against TensorRT version 0.0.0\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "/home/kamgo/Verkehrszeichenerkennung/jupyter/../Models/TensorRT/frozen_model_trt.pb; No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-815521f53b66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# save Frozen-Graph von TensorRT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mgfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFastGFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfr_graph_trt_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrt_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSerializeToString\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/py36/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, file_content)\u001b[0m\n\u001b[1;32m    104\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;34m\"\"\"Writes file_content to the file. Appends to the end of the file.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prewrite_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     pywrap_tensorflow.AppendToFile(\n\u001b[1;32m    108\u001b[0m         compat.as_bytes(file_content), self._writable_file)\n",
      "\u001b[0;32m~/py36/lib/python3.6/site-packages/tensorflow/python/lib/io/file_io.py\u001b[0m in \u001b[0;36m_prewrite_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     90\u001b[0m                                            \"File isn't open for writing\")\n\u001b[1;32m     91\u001b[0m       self._writable_file = pywrap_tensorflow.CreateWritableFile(\n\u001b[0;32m---> 92\u001b[0;31m           compat.as_bytes(self.__name), compat.as_bytes(self.__mode))\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_prepare_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: /home/kamgo/Verkehrszeichenerkennung/jupyter/../Models/TensorRT/frozen_model_trt.pb; No such file or directory"
     ]
    }
   ],
   "source": [
    "# Erstellung von TRT-Frozen-Model\n",
    "## read tensorflozen-Graph\n",
    "with tf.gfile.GFile(fr_graph_tf_model, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "trt_graph = trt.create_inference_graph(input_graph_def=graph_def,outputs=[\"dense_1/Softmax\"], max_batch_size=2,max_workspace_size_bytes=2*(10**9), precision_mode=\"FP32\")\n",
    "# save Frozen-Graph von TensorRT\n",
    "with gfile.FastGFile(fr_graph_trt_model, \"wb\") as f:\n",
    "    f.write(trt_graph.SerializeToString())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Improve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "IMG_SIZE = 48\n",
    "input_node = \"conv2d_input:0\"\n",
    "output_node = \"dense_1/Softmax:0\"\n",
    "pfad_beschreibung = os.path.join(base_path,\"../Daten/utils/Text_Beschreibung.csv\")\n",
    "classe_label = pd.read_csv(pfad_beschreibung)\n",
    "classe_label = classe_label.set_index('ClassId').T.to_dict()\n",
    "\n",
    "# Bilder werden einglesen im RGB-Format\n",
    "img1 = cv2.imread(\"00000_00010.ppm\", cv2.IMREAD_UNCHANGED)\n",
    "print(\"gelesen wird:\",classe_label[0]['SignName'])\n",
    "img2 = cv2.imread(\"00000_00006.ppm\", cv2.IMREAD_UNCHANGED)\n",
    "print(\"gelesen wird:\",classe_label[3]['SignName'])\n",
    "\n",
    "image1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "image2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#image preporcessing\n",
    "image1 = cv2.resize(image1, (IMG_SIZE,IMG_SIZE), interpolation = cv2.INTER_AREA) \n",
    "image2 = cv2.resize(image2, (IMG_SIZE,IMG_SIZE), interpolation = cv2.INTER_AREA) \n",
    "\n",
    "images = [image1, image2]\n",
    "labels_classes = [0, 3]\n",
    "\n",
    "# show image\n",
    "fig=plt.figure(figsize=(4, 4))\n",
    "columns = 2\n",
    "rows = 1\n",
    "count = 1\n",
    "for real_image in zip(images, labels_classes):\n",
    "    fig.add_subplot(rows, columns,count)\n",
    "    count +=1\n",
    "    real_label = classe_label[real_image[1]]['SignName']\n",
    "    real_label = real_label.replace(\" \", \"\\n\")\n",
    "    plt.title(real_label)\n",
    "    plt.imshow(real_image[0])       \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_model(path_frozen_graph, input_node, output_node, input_img):\n",
    "    \"\"\"\n",
    "    Diese funktion wird daf√ºr helfen, irgenwelches Model(Tensorflow/TensorRt)\n",
    "    anzuwenden\n",
    "    \"\"\"\n",
    "    gpu_option = tf.GPUOptions(per_process_gpu_memory_fraction=0.50)\n",
    "    frozen_graph = tf.Graph()\n",
    "    with frozen_graph.as_default():\n",
    "        with tf.Session(config=tf.ConfigProto(gpu_options=gpu_option)) as sess:\n",
    "            print(\"der Graph wird gelesen!\")\n",
    "            with tf.gfile.GFile(fr_graph_tf_model, \"rb\") as f:\n",
    "                frozen_graph = tf.GraphDef()\n",
    "                frozen_graph.ParseFromString(f.read())\n",
    "            print(\"der wurde gelesen!\")\n",
    "\n",
    "            # Auswahl von input und output\n",
    "            tf.import_graph_def(frozen_graph, name='')\n",
    "            input_tensor = sess.graph.get_tensor_by_name(input_node)\n",
    "            output_tensor = sess.graph.get_tensor_by_name(output_node)\n",
    "\n",
    "            total_time = 0\n",
    "            n_time_inference = 50\n",
    "            input_img = input_img.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "            out_pred = sess.run(output_tensor,\n",
    "                                feed_dict={input_tensor: input_img})\n",
    "\n",
    "            for i in range(n_time_inference):\n",
    "                t1 = time.time()\n",
    "                out_pred = sess.run(output_tensor,\n",
    "                                    feed_dict={input_tensor: input_img})\n",
    "                t2 = time.time()\n",
    "                delta_time = t2 - t1\n",
    "                total_time += delta_time\n",
    "                print(\"gebrauchte Zeit - \" + str(i) + \": \", delta_time)\n",
    "            print(\"mittelre Zeit: {}\".format(total_time/n_time_inference))\n",
    "            mittelre_zeit = total_time/n_time_inference\n",
    "    return out_pred, mittelre_zeit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frozen -Graph TensorRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = []\n",
    "sum_zeit=0\n",
    "for image in images:\n",
    "    prediction, zeit = perform_model(fr_graph_tf_model,\n",
    "                                     input_node,\n",
    "                                     output_node,\n",
    "                                     image)\n",
    "    prediction_classes.append(prediction)\n",
    "    sum_zeit += zeit\n",
    "\n",
    "# show image\n",
    "fig=plt.figure(figsize=(4, 4))\n",
    "columns = 2\n",
    "rows = 2\n",
    "count = 1\n",
    "for image, label_class,predicted_class in zip(images, labels_classes, prediction_classes):\n",
    "    fig.add_subplot(rows, columns,count)\n",
    "    count +=1\n",
    "    real_label = classe_label[label_class]['SignName']\n",
    "    real_label = real_label.replace(\" \", \"\\n\")\n",
    "    predicted_label = classe_label[np.argmax(predicted_class[0])]['SignName']\n",
    "    predicted_label = predicted_label.replace(\" \", \"\\n\")\n",
    "    plt.title(\"Das Model hat predictd: {}\\n und Rictig ist: {}\\n\".format(predicted_label, real_label))\n",
    "    plt.imshow(image)\n",
    "label = 'Ergebnisse von Tensorflow in {} secunde Zeit '.format(sum_zeit/len(images))\n",
    "fig.suptitle(label, fontsize=16, fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = []\n",
    "sum_zeit=0\n",
    "for image in images:\n",
    "    prediction, zeit = perform_model(fr_graph_trt_model,\n",
    "                                     input_node,\n",
    "                                     output_node,\n",
    "                                     image)\n",
    "    prediction_classes.append(prediction)\n",
    "    sum_zeit += zeit\n",
    "\n",
    "# show image\n",
    "fig=plt.figure(figsize=(4, 4))\n",
    "columns = 2\n",
    "rows = 2\n",
    "count = 1\n",
    "for image, label_class,predicted_class in zip(images, labels_classes, prediction_classes):\n",
    "    fig.add_subplot(rows, columns,count)\n",
    "    count +=1\n",
    "    real_label = classe_label[label_class]['SignName']\n",
    "    real_label = real_label.replace(\" \", \"\\n\")\n",
    "    predicted_label = classe_label[np.argmax(predicted_class[0])]['SignName']\n",
    "    predicted_label = predicted_label.replace(\" \", \"\\n\")\n",
    "    plt.title(\"Das Model hat predictd: {}\\n und Rictig ist: {}\\n\".format(predicted_label, real_label))\n",
    "    plt.imshow(image)\n",
    "label = 'Ergebnisse von Tensorflow in {} secunde Zeit '.format(sum_zeit/len(images))\n",
    "fig.suptitle(label, fontsize=16, fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
