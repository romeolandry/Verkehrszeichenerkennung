{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pratische Umwandlung des Keras-Model zu TensorRT-Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras-Model zu tensorflow-Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.tensorrt as trt\n",
    "import tensorflow.keras as tfk\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.compat.v1.graph_util import convert_variables_to_constants\n",
    "from tensorflow.python.platform import gfile\n",
    "from tensorflow.python.tools import freeze_graph\n",
    "import random\n",
    "random.seed(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras zu Tensorflow-Frozen Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/kamgo/Donnees/Master_projekt/TensorRT/env_TRT/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/kamgo/Donnees/Master_projekt/TensorRT/env_TRT/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /home/kamgo/Donnees/Master_projekt/TensorRT/env_TRT/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Tensor(\"conv2d_input:0\", shape=(?, 48, 48, 3), dtype=float32)\n",
      "WARNING:tensorflow:From <ipython-input-2-244fbbfa1be9>:21: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-244fbbfa1be9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m                            \u001b[0mtf_model_pfad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m                            \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_model\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m                            outputs=output_model)\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# das model wird jetzt compiliert werden\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Donnees/Master_projekt/TensorRT/env_TRT/lib/python3.7/site-packages/tensorflow/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Donnees/Master_projekt/TensorRT/env_TRT/lib/python3.7/site-packages/tensorflow/python/saved_model/simple_save.py\u001b[0m in \u001b[0;36msimple_save\u001b[0;34m(session, export_dir, inputs, outputs, legacy_init_op)\u001b[0m\n\u001b[1;32m     79\u001b[0m   signature_def_map = {\n\u001b[1;32m     80\u001b[0m       \u001b[0msignature_constants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_SERVING_SIGNATURE_DEF_KEY\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m           \u001b[0msignature_def_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_signature_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m   }\n\u001b[1;32m     83\u001b[0m   \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSavedModelBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexport_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Donnees/Master_projekt/TensorRT/env_TRT/lib/python3.7/site-packages/tensorflow/python/saved_model/signature_def_utils_impl.py\u001b[0m in \u001b[0;36mpredict_signature_def\u001b[0;34m(inputs, outputs)\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m   \"\"\"\n\u001b[0;32m--> 195\u001b[0;31m   \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prediction inputs cannot be None or empty.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Donnees/Master_projekt/TensorRT/env_TRT/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    688\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m     \"\"\"\n\u001b[0;32m--> 690\u001b[0;31m     raise TypeError(\"Using a `tf.Tensor` as a Python `bool` is not allowed. \"\n\u001b[0m\u001b[1;32m    691\u001b[0m                     \u001b[0;34m\"Use `if t is not None:` instead of `if t:` to test if a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                     \u001b[0;34m\"tensor is defined, and use TensorFlow ops such as \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Using a `tf.Tensor` as a Python `bool` is not allowed. Use `if t is not None:` instead of `if t:` to test if a tensor is defined, and use TensorFlow ops such as tf.cond to execute subgraphs conditioned on the value of a tensor."
     ]
    }
   ],
   "source": [
    "keras_model_pfad = \"/home/kamgo/Donnees/Master_projekt/TensorRT/Verkehrszeichnerkennung/Models/Keras-Model/signs_model_Kalssifikation_2019_10_19_20_58_53.h5\"\n",
    "tf_model_pfad = \"/home/kamgo/Schreibtisch/Models/Tensor_\"\n",
    "fr_graph_tf_model = tf_model_pfad + \"frozen_model_tf.pb\"\n",
    "fr_graph_trt_model = \"/home/kamgo/Schreibtisch/Models/TensorRT\" + \"frozen_model_trt.pb\"\n",
    "\n",
    "tf.keras.backend.set_learning_phase(0) # falls das keras-Model mit Batchnormalisation trainiert wurde\n",
    "\n",
    "#model = load_model(keras_model_pfad)\n",
    "model = load_model(keras_model_pfad)\n",
    "sess = tfk.backend.get_session()\n",
    "\n",
    "# get input und output des models for tensorflow improvement\n",
    "input_model = model.inputs[0]\n",
    "print(input_model)\n",
    "output_model = model.outputs[0]\n",
    "\n",
    "# save tensort-Graph\n",
    "tf.saved_model.simple_save(sess,\n",
    "                           tf_model_pfad,\n",
    "                           inputs=input_model,\n",
    "                           outputs=output_model)\n",
    "\n",
    "# das model wird jetzt compiliert werden\n",
    "freeze_graph.freeze_graph(None,\n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  model.outputs[0].op.name,\n",
    "                                  None,\n",
    "                                  None,\n",
    "                                  fr_graph_tf_model,\n",
    "                                  False,\n",
    "                                  \"\",\n",
    "                                  input_saved_model_dir=tf_model_pfad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow-frozen  zu TRT_Frozen-Model(.pb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstellung von TRT-Frozen-Model\n",
    "## read tensorflozen-Graph\n",
    "with tf.gfile.GFile(fr_graph_tf_model, \"rb\") as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "trt_graph = trt.create_inference_graph(input_graph_def=tf_frozen_graph,outputs=output_models, max_batch_size=2,max_workspace_size_bytes=2*(10**9), precision_mode=\"FP32\")\n",
    "# save Frozen-Graph von TensorRT\n",
    "with gfile.FastGFile(fr_graph_trt_model, \"wb\") as f:\n",
    "    f.write(trt_graph.SerializeToString()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Improve Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_model(path_frozen_graph, input_node, output_node, input_img):\n",
    "    \"\"\"\n",
    "    Diese funktion wird dazu helfen, irgenwelches Model(Tensorflow/TensorRt)\n",
    "    anzuwenden\n",
    "    \"\"\"\n",
    "    gpu_option = tf.GPUOptions(per_process_gpu_memory_fraction=0.50)\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        with tf.Session(config=tf.ConfigProto(gpu_options=gpu_option)) as sess:\n",
    "            print(\"der Graph wird gelesen!\")\n",
    "            frozen_graph = loard_model_graph(path_frozen_graph)\n",
    "            print(\"der wurde gelesen!\")\n",
    "\n",
    "            # Auswahl von input und output\n",
    "            tf.import_graph_def(frozen_graph, name='')\n",
    "            input_tensor = sess.graph.get_tensor_by_name(input_node)\n",
    "            output_tensor = sess.graph.get_tensor_by_name(output_node)\n",
    "\n",
    "            total_time = 0\n",
    "            n_time_inference = 50\n",
    "            input_img = input_img.reshape(-1, cfg.IMG_SIZE, cfg.IMG_SIZE, 3)\n",
    "            out_pred = sess.run(output_tensor,\n",
    "                                feed_dict={input_tensor: input_img})\n",
    "\n",
    "            for i in range(n_time_inference):\"dense_1/Softmax:0\"\n",
    "                t1 = time.time()\n",
    "                out_pred = sess.run(output_tensor,\n",
    "                                    feed_dict={input_tensor: input_img})\n",
    "                t2 = time.time()\n",
    "                delta_time = t2 - t1\n",
    "                total_time += delta_time\n",
    "                print(\"gebrauchte Zeit - \" + str(i) + \": \", delta_time)\n",
    "            print(\"mittelre Zeit: {}\".format(total_time/n_time_inference))\n",
    "            mittelre_zeit = total_time/n_time_inference\n",
    "    return out_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "\n",
    "IMG_SIZE = 48\n",
    "input_node = \"conv2d_input:0\"\n",
    "output_node = \"dense_1/Softmax:0\"\n",
    "pfad_beschreibung = \"/home/kamgo/Donnees/Master_projekt/TensorRT/Verkehrszeichnerkennung/Daten/utils/Text_Beschreibung.csv\"\n",
    "classe_label = pd.read_csv(pfad_beschreibung)\n",
    "classe_label = classe_label.set_index('ClassId').T.to_dict()\n",
    "\n",
    "# Bilder werden einglesen im RGB-Format\n",
    "img1 = cv2.imread(\"00000_00010.ppm\", cv2.IMREAD_UNCHANGED)\n",
    "print(\"gelesen wird:\",classe_label[0]['SignName'])\n",
    "img2 = cv2.imread(\"00000_00006.ppm\", cv2.IMREAD_UNCHANGED)\n",
    "print(\"gelesen wird:\",classe_label[3]['SignName'])\n",
    "\n",
    "image1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
    "image2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "#image preporcessing\n",
    "image1 = cv2.resize(image1, (IMG_SIZE,IMG_SIZE), interpolation = cv2.INTER_AREA) \n",
    "image2 = cv2.resize(image2, (IMG_SIZE,IMG_SIZE), interpolation = cv2.INTER_AREA) \n",
    "\n",
    "images = [image1, image2]\n",
    "labels_classes = [0, 3]\n",
    "\n",
    "# show image\n",
    "fig=plt.figure(figsize=(4, 4))\n",
    "columns = 2\n",
    "rows = 1\n",
    "count = 1\n",
    "for real_image in zip(images, labels_classes):\n",
    "    fig.add_subplot(rows, columns,count)\n",
    "    count +=1\n",
    "    real_label = classe_label[real_image[1]]['SignName']\n",
    "    real_label = real_label.replace(\" \", \"\\n\")\n",
    "    plt.title(real_label)\n",
    "    plt.imshow(real_image[0])       \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_model(path_frozen_graph, input_node, output_node, input_img):\n",
    "    \"\"\"\n",
    "    Diese funktion wird dafür helfen, irgenwelches Model(Tensorflow/TensorRt)\n",
    "    anzuwenden\n",
    "    \"\"\"\n",
    "    gpu_option = tf.GPUOptions(per_process_gpu_memory_fraction=0.50)\n",
    "    graph = tf.Graph()\n",
    "    with graph.as_default():\n",
    "        with tf.Session(config=tf.ConfigProto(gpu_options=gpu_option)) as sess:\n",
    "            print(\"der Graph wird gelesen!\")\n",
    "            frozen_graph = loard_model_graph(path_frozen_graph)\n",
    "            print(\"der wurde gelesen!\")\n",
    "\n",
    "            # Auswahl von input und output\n",
    "            tf.import_graph_def(frozen_graph, name='')\n",
    "            input_tensor = sess.graph.get_tensor_by_name(input_node)\n",
    "            output_tensor = sess.graph.get_tensor_by_name(output_node)\n",
    "\n",
    "            total_time = 0\n",
    "            n_time_inference = 50\n",
    "            input_img = input_img.reshape(-1, cfg.IMG_SIZE, cfg.IMG_SIZE, 3)\n",
    "            out_pred = sess.run(output_tensor,\n",
    "                                feed_dict={input_tensor: input_img})\n",
    "\n",
    "            for i in range(n_time_inference):\n",
    "                t1 = time.time()\n",
    "                out_pred = sess.run(output_tensor,\n",
    "                                    feed_dict={input_tensor: input_img})\n",
    "                t2 = time.time()\n",
    "                delta_time = t2 - t1\n",
    "                total_time += delta_time\n",
    "                print(\"gebrauchte Zeit - \" + str(i) + \": \", delta_time)\n",
    "            print(\"mittelre Zeit: {}\".format(total_time/n_time_inference))\n",
    "            mittelre_zeit = total_time/n_time_inference\n",
    "    return out_pred, mittelre_zeit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = []\n",
    "sum_zeit=0\n",
    "for image in images:\n",
    "    prediction, zeit = perform_model(fr_graph_tf_model,\n",
    "                                     input_node,\n",
    "                                     output_node,\n",
    "                                     image)\n",
    "    prediction_classes.add(prediction)\n",
    "    sum_zeit += zeit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show image\n",
    "fig=plt.figure(figsize=(4, 4))\n",
    "columns = 2\n",
    "rows = 2\n",
    "count = 1\n",
    "for real_image in zip(images, labels_classes, prediction_classes):\n",
    "    fig.add_subplot(rows, columns,count)\n",
    "    count +=1\n",
    "    real_label = classe_label[real_image[1]]['SignName']\n",
    "    real_label = real_label.replace(\" \", \"\\n\")\n",
    "    predicted_label = classe_label[real_image[2]]['SignName']\n",
    "    predicted_label = predicted_label.replace(\" \", \"\\n\")\n",
    "    plt.title(\"Das Model hat predictd: {}\\n und Rictig ist: {}\\n\".format(predicted_label, real_label))\n",
    "    plt.imshow(real_image[0])\n",
    "label = 'Ergebnisse von Tensorflow in {} secunde Zeit '.format(sum_zeit/len(images))\n",
    "fig.suptitle(label, fontsize=16, fontweight=\"bold\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tensorflow - Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_classes = []\n",
    "sum_zeit=0\n",
    "for image in images:\n",
    "    prediction, zeit = perform_model(fr_graph_tf_model,\n",
    "                                     input_node,\n",
    "                                     output_node,\n",
    "                                     image)\n",
    "    prediction_classes.add(prediction)\n",
    "    sum_zeit += zeit\n",
    "\n",
    "# show image\n",
    "fig=plt.figure(figsize=(4, 4))\n",
    "columns = 2\n",
    "rows = 2\n",
    "count = 1\n",
    "for real_image in zip(images, labels_classes, prediction_classes):\n",
    "    fig.add_subplot(rows, columns,count)\n",
    "    count +=1\n",
    "    real_label = classe_label[real_image[1]]['SignName']\n",
    "    real_label = real_label.replace(\" \", \"\\n\")\n",
    "    predicted_label = classe_label[real_image[2]]['SignName']\n",
    "    predicted_label = predicted_label.replace(\" \", \"\\n\")\n",
    "    plt.title(\"Das Model hat predictd: {}\\n und Rictig ist: {}\\n\".format(predicted_label, real_label))\n",
    "    plt.imshow(real_image[0])\n",
    "label = 'Ergebnisse von TensorRT in {} secunde Zeit '.format(sum_zeit/len(images))\n",
    "fig.suptitle(label, fontsize=16, fontweight=\"bold\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
